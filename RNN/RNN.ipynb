{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "\n",
    "# .load_data_time_machine() is implemented in language-model.ipynb\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use one_hot encoding\n",
    "# Assume we have len(vocab) = 3,\n",
    "# then 0 = [1, 0, 0], 1 = [0, 1, 0], 2 = [0, 0, 1]\n",
    "F.one_hot(torch.tensor([0, 2]), len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to initialize parameters of RNN\n",
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - vocab_size: length of our input vocabulary list. eg: [\"I\", \"like\", \"fruit\"] has a length of 3\n",
    "    - num_hiddens: number of hidden neurons\n",
    "    - device: CPU or GPU\n",
    "\n",
    "    Returns:\n",
    "    [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    \"\"\"\n",
    "    num_inputs = num_outputs = vocab_size \n",
    "\n",
    "    # This is a nested function for parameter initialization \n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "    \n",
    "    W_xh = normal((num_inputs), num_hiddens)  # Weight vector from input layer to hidden layer\n",
    "    W_hh = normal((num_hiddens, num_hiddens)) # W V from previous hidden layer to current hidden layer\n",
    "    b_h = torch.zero(num_hiddens, device=device) # bias vector -- y_hidden = W_xh @ X_input + W_hh @ previous_hidden + b_h\n",
    "    W_hq = normal((num_hiddens, num_outputs)) # W V from hidden layer to output layer\n",
    "    b_q = torch.zeros(num_outputs, device=device) # bias vector used for the output\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "\n",
    "    # Set .requires_grad_(True) for training\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model function RNN\n",
    "def rnn(inputs, state, params):\n",
    "    \"\"\"\n",
    "    Implements a simple Recurrent Neural Network (RNN) forward pass.\n",
    "\n",
    "    Args:\n",
    "    - inputs: List of input tensors, each with shape (n, h), where:\n",
    "        n = batch size (number of samples processed in parallel)\n",
    "        h = input feature dimension\n",
    "    - state: Tuple containing the initial hidden state, (H,), where:\n",
    "        H has shape (n, h) and represents the hidden state of the RNN\n",
    "    - params: Tuple containing model parameters:\n",
    "        W_xh: Weight matrix for input-to-hidden connection (shape: h x h)\n",
    "        W_hh: Weight matrix for hidden-to-hidden transition (shape: h x h)\n",
    "        b_h: Bias vector for hidden state computation (shape: 1 x h)\n",
    "        W_hq: Weight matrix for hidden-to-output transformation (shape: h x q)\n",
    "        b_q: Bias vector for output computation (shape: 1 x q)\n",
    "\n",
    "    Returns:\n",
    "    - outputs: Tensor of shape (a * n, q), where:\n",
    "        a = number of time steps (length of inputs list)\n",
    "        n = batch size\n",
    "        q = output dimension\n",
    "    - final_state: Tuple containing the final hidden state (H,), where H has shape (n, h)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack model parameters\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "\n",
    "    # Unpack the initial hidden state\n",
    "    H, = state  # H has shape (n, h)\n",
    "\n",
    "    # List to store output tensors at each time step\n",
    "    outputs = []\n",
    "\n",
    "    # Iterate over the input sequence (loop over time steps)\n",
    "    for X in inputs:\n",
    "        \"\"\"\n",
    "        Compute the new hidden state:\n",
    "        H = tanh(X @ W_xh + H @ W_hh + b_h)\n",
    "        \n",
    "        Explanation:\n",
    "        - X @ W_xh: Projects input X into the hidden space (shape: n x h)\n",
    "        - H @ W_hh: Applies transformation to the previous hidden state (shape: n x h)\n",
    "        - b_h: Bias term added to the hidden state (shape: 1 x h, broadcasted to n x h)\n",
    "        - tanh: Non-linear activation function to introduce non-linearity\n",
    "        \"\"\"\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)  # H shape: (n, h)\n",
    "\n",
    "        \"\"\"\n",
    "        Compute the output Y at the current time step:\n",
    "        Y = H @ W_hq + b_q\n",
    "        \n",
    "        Explanation:\n",
    "        - H @ W_hq: Maps hidden state to output space (shape: n x q)\n",
    "        - b_q: Bias term for output transformation (shape: 1 x q, broadcasted to n x q)\n",
    "        \"\"\"\n",
    "        Y = torch.mm(H, W_hq) + b_q  # Y shape: (n, q)\n",
    "\n",
    "        # Store the output for this time step\n",
    "        outputs.append(Y)  # List of shape (a elements, each of shape n x q)\n",
    "\n",
    "    \"\"\"\n",
    "    Concatenate all output tensors along the first dimension:\n",
    "    - Since outputs is a list of a tensors, each of shape (n, q), we stack them\n",
    "    - The resulting tensor has shape (a * n, q), effectively flattening time dimension\n",
    "    \"\"\"\n",
    "    return torch.cat(outputs, dim=0), (H,)  # Final output shape: (a * n, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel:\n",
    "    def __init__(self, vocab_size, num_hiddens, device, get_params, init_state, forward_fn):\n",
    "        \"\"\"\n",
    "        Initializes the RNN model.\n",
    "\n",
    "        Args:\n",
    "        - vocab_size: Integer, the size of the vocabulary (number of unique tokens).\n",
    "        - num_hiddens: Integer, the number of hidden units in the RNN.\n",
    "        - device: The device (CPU/GPU) on which computations should be performed.\n",
    "        - get_params: Function that returns the model parameters (weights and biases).\n",
    "        - init_state: Function that initializes the hidden state.\n",
    "        - forward_fn: Function that implements the forward pass of the RNN.\n",
    "\n",
    "        Returns:\n",
    "        - Initializes the RNN model with parameters, state initialization, and forward function.\n",
    "        \"\"\"\n",
    "\n",
    "        # Store hyperparameters\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens  \n",
    "\n",
    "        # Obtain the model parameters (e.g., weight matrices and biases)\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "\n",
    "        # Store the functions for state initialization and forward propagation\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "    \n",
    "    # This function is called when the class get instantiated, for example. RNN = RNNModel(param1,...) will call the function below by default\n",
    "    def __call__(self, X, state):\n",
    "        \"\"\"\n",
    "        Defines how the model processes input X and updates its hidden state.\n",
    "\n",
    "        Args:\n",
    "        - X: Tensor of shape (batch_size, sequence_length), representing a batch of tokenized sequences.\n",
    "        - state: Tuple containing the hidden state(s).\n",
    "\n",
    "        Returns:\n",
    "        - output: The output tensor produced by the RNN.\n",
    "        - updated state: The hidden state after processing the input.\n",
    "\n",
    "        Steps:\n",
    "        1. Convert input X into a one-hot representation:\n",
    "           - Shape transformation: (batch_size, sequence_length) â†’ (sequence_length, batch_size, vocab_size)\n",
    "        2. Convert the one-hot encoding to float type for matrix operations.\n",
    "        3. Call `forward_fn` to process the input through the RNN and get the output and new state.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert input indices into a one-hot encoded representation\n",
    "        # X.T is used to swap batch_size and sequence_length dimensions\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)  \n",
    "        # Shape after one-hot encoding: (sequence_length, batch_size, vocab_size)\n",
    "\n",
    "        # Perform forward pass using the RNN function\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "    \n",
    "    def begin_state(self, batch_size, device):\n",
    "        \"\"\"\n",
    "        Initializes the hidden state for the RNN.\n",
    "\n",
    "        Args:\n",
    "        - batch_size: Integer, the number of sequences in the batch.\n",
    "        - device: The device (CPU/GPU) where computations will run.\n",
    "\n",
    "        Returns:\n",
    "        - Initial hidden state of the RNN.\n",
    "        \"\"\"\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2lEnvLimu3-9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
